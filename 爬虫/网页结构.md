了解网页结构是用python进行爬虫的前提。  
# 网页基本组成部分
网页主要的组成是HTML（上课讲过），CSS和JavaScript（用以表现出HTML的内容）  
## HTML介绍

# 用python登陆网页
利用python自带的库就可以打开网页（以下是python3之下的代码）  
```python
from urllib import urlopen
#url就是指网页的链接

html = urlopen('网页链接').read().decode('utf-8')
#decode('utf-8')用于解析中文内容
```
这样就用python读取出了网页源码
# 匹配网页内容
读取网页html后，我们需要筛选出其中需要的内容。一般我们会用正则表达式来进行这个工作。  
当然对于复杂的网站，以我们的能力难以用正则表达式来实现。我们可以借助BeautifulSoup库。
## 正则表达式(Regular Expression)
正则表达式是用来匹配字符的一种工具，找到文本中的特定内容，也刚好可以用于爬虫中对网页源代码的筛选。
```python
#在python中可以直接导入正则的库
import re
```
### 1、re.search()
re.search(查找的字符串, 文本)  
若文本中存在查找的内容，则返回一个match的object；若没有，则返回none  
### 2、r“”
现在我们想通过正则表达式表达一类我们想搜索的字符串，这种特殊的字符串就要在“”前面➕️一个r，用来表明他是正则表达式的字符串。在配合上各种正则表达式的规则，就可以实现多样的字符表达。  
**用[]包括所有想搜寻的字符**  
例如[ac]就表示是a或者c都可以，[A-Z]就表示了所有大写的英文字母，[0-9a-z]就表示了所有数字和小写英文字母。如果我们想搜索run和ran，那我们就可以用 **r"r[au]n"** 这样来表达。  
## 3、其他的固有规则  
\d : 任何数字  
\D : 不是数字  
\s : 任何 white space, 如 [\t\n\r\f\v]  
\S : 不是 white space  
\w : 任何大小写字母, 数字和 “” [a-zA-Z0-9]  
\W : 不是 \w  
\b : 空白字符 (只在某个字的开头或结尾)  
\B : 空白字符 (不在某个字的开头或结尾)  
\\ : 匹配 \  
. : 匹配任何字符 (除了 \n)  
^ : 匹配开头  
$ : 匹配结尾  
? : 前面的字符可有可无  
同样用这些特殊字符结合其他字符组成我们想要的正则字符串，例如r"·a"表示任何字符加一个a。  
  
**flags=re.M**  
如果一个字符串有很多行, 在用 ^ 来匹配行开头的字符时，只能检索第一行。这时要用到flags=re.M, 或者这样写也行 flags=re.MULTILINE。  
例如我们要检索多行的一个字符串每一行开头是否都有y，我们可以这样表示  
```python
re.search(r"^y", 查找范围, flags = re.M)
```
## 4、重复匹配
\* : 重复零次或多次  
\+ : 重复一次或多次  
{n, m} : 重复 n 至 m 次  
{n} : 重复 n 次  
将这些符号放在字符的后面形成组合，例如 b* 就表示b这个字符重复0或多次。  
如果我想匹配abbbbc，其中的b无论有几个（包括0）  
```python
re.search(r"ab*c", 查找范围)
```




