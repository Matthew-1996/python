了解网页结构是用python进行爬虫的前提。  
# 网页基本组成部分
网页主要的组成是HTML（上课讲过），CSS和JavaScript（用以表现出HTML的内容）  
## HTML介绍

# 用python登陆网页
利用python自带的库就可以打开网页（以下是python3之下的代码）  
```python
from urllib import urlopen
#url就是指网页的链接

html = urlopen('网页链接').read().decode('utf-8')
#decode('utf-8')用于解析中文内容
```
这样就用python读取出了网页源码
# 匹配网页内容
读取网页html后，我们需要筛选出其中需要的内容。一般我们会用正则表达式来进行这个工作。  
当然对于复杂的网站，以我们的能力难以用正则表达式来实现。我们可以借助BeautifulSoup库。
## 正则表达式(Regular Expression)
正则表达式是用来匹配字符的一种工具，找到文本中的特定内容，也刚好可以用于爬虫中对网页源代码的筛选。
```python
#在python中可以直接导入正则的库
import re
```
### 1、re.search()
re.search(查找的字符串, 文本)  
若文本中存在查找的内容，则返回一个match的object；若没有，则返回none  
### 2、r“”
现在我们想通过正则表达式表达一类我们想搜索的字符串，这种特殊的字符串就要在“”前面➕️一个r，用来表明他是正则表达式的字符串。在配合上各种正则表达式的规则，就可以实现多样的字符表达。  
**用[]包括所有想搜寻的字符**  
例如[ac]就表示是a或者c都可以，[A-Z]就表示了所有大写的英文字母，[0-9a-z]就表示了所有数字和小写英文字母。如果我们想搜索run和ran，那我们就可以用 **r"r[au]n"** 这样来表达。  
## 3、其他的固有规则  
\d : 任何数字  
\D : 不是数字  
\s : 任何 white space, 如 [\t\n\r\f\v]  
\S : 不是 white space  
\w : 任何大小写字母, 数字和 “” [a-zA-Z0-9]  
\W : 不是 \w  
\b : 空白字符 (只在某个字的开头或结尾)  
\B : 空白字符 (不在某个字的开头或结尾)  
\\ : 匹配 \  
. : 匹配任何字符 (除了 \n)  
^ : 匹配开头  
$ : 匹配结尾  
? : 前面的字符可有可无  
同样用这些特殊字符结合其他字符组成我们想要的正则字符串，例如r"·a"表示任何字符加一个a。  
  
**flags=re.M**  
如果一个字符串有很多行, 在用 ^ 来匹配行开头的字符时，只能检索第一行。这时要用到flags=re.M, 或者这样写也行 flags=re.MULTILINE。  
例如我们要检索多行的一个字符串每一行开头是否都有y，我们可以这样表示  
```python
re.search(r"^y", 查找范围, flags = re.M)
```
## 4、重复匹配
\* : 重复零次或多次  
\+ : 重复一次或多次  
{n, m} : 重复 n 至 m 次  
{n} : 重复 n 次  
将这些符号放在字符的后面形成组合，例如 b* 就表示b这个字符重复0或多次。  
如果我想匹配abbbbc，其中的b无论有几个（包括0）  
```python
re.search(r"ab*c", 查找范围)
```
## 5、分组.group()
当我们要找的内容不止一个的时候，我们可以用.group()来分组。这样就可以在所有匹配的内容中确定我们这次想输出的部分。  
利用 ?p<命名> 还可以对每个组进行命名
例如：  
```python
a = r"id:(\d+), date:(.+)"
#结合刚才所学，\d+表示任何数字重复一次以上，.+表示任何字符重复一次以上。首先我们分别用()表示表示为两个组。
#现在用a去匹配一串字符，并结合match.group()函数实现部分的输出
b = re.search(a, "id:1233, date:Feb/11/11")
b.group()
#如果不填写参数，就是全部都输出，等于b。若将它print()，则会是id:1233, date:Feb/11/11
b.group(1)
#这表示返回第一组（括号）里的内容。若将它print()，则会是1233
b.group(2)
#这表示返回第一组（括号）里的内容。若将它print()，则会是Feb/11/11

#当分组多的时候，用数字表示可能麻烦，就可以用?p<>
c = r'id:(?p<id>\d+), date:(?p<date>.+)'
d = re.search(c, "id:1233, date:Feb/11/11")
print(d.group('id'))
#结果是1233
```
## findall找到全部匹配项
顾名思义，直接看用法,用法也跟search差不多  
```python
re.findall(r'a|b', 'cbhdfiwhfiw')  
```
## re.sub()，字符替换
顾名思义就是用新字符串来替换文本中原有的字符串,这个用法比python自带的.replace()更加灵活  
```python
re.sub(r'a', 'b', 'ac')
#上面的顺序依次是匹配字符、替换字符、查找文本
#返回结果为bc
```
# re.split字符分割
功能和python的string.split('')类似
```python
re.split(r',;/.', 'a,b;c.d')
# 注意由于.本身表所有字符，为了表示它就是句号，加了转译的\
#返回结果会是[a, b, c, d]的一个列表
```
# re.compile
这个功能是为了整合某个重复的正则表达式，这样就简化了代码量
```python
#首先我们把一个正则表达式compile
compile_re = re.compile(r'a[bc]d')
#我们现在用comlipe_re表达了正则表达式，之后就可以用其他re的函数
compile_re.search('acdhnuugk')
#search里面就直接输入匹配文本就好了
```
## 开始匹配
正则表达式是匹配网页文本的一种手段，接下来说明一下匹配的步骤。  
比如利用html的tag
假如我们要找html标题中的内容，html的格式是这样的：
```html
<title>标题内容</title>
```
那么我们就借助这个tag去找
```python
#结合前面学的内容
from urllib import urlopen
import re
html1 = urlopen('网址').read().decode('utf-8')
re1 = re.findall(r'<title>(.+?)</title>', html)
#再调整一下输出的形式
print('\ntitle is:', re1[0])
#输出多个title用\n来清晰
```
如果想要找到中间的段落\<p\>,我们使用 flags=re.DOTALL, 因为这个段落在 HTML 中还夹杂着换行, 用flags=re.DOTALL 来对这些 tab, new line 不敏感 
  
```python
re2 = re.findall(r"<p>(.*?)</p>", html1, flags=re.DOTALL)    # re.DOTALL if multi line
print("\nPage paragraph is: ", re2[0])
```
同理，我们找链接，链接用href=表示  
```python
re3 = re.findall(r'href="(.*?)"', html)
print('\nall link is:', re3[0])
```




